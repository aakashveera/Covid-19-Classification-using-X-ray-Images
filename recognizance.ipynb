{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator is used to load the images from the respective Directory with the mentioned batch size and Image size, also several augments of the image can also be made with the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Here the given list of augments has been made to improve the learning.</b>\n",
    "\n",
    "1)Width Shift (Shifting the Image Horizontally)\n",
    "\n",
    "2)Height Shift (Shifting the Image Vertically)\n",
    "\n",
    "3)Rescale (Converting the pixel values from 0 - 255 to 0 - 1)\n",
    "\n",
    "4)Shear (Shifting one part of a Image) <a href=\"https://docs.gimp.org/2.10/en/gimp-tool-shear.html#:~:text=Shear%20tool%20is%20used%20to,A%20rectangle%20becomes%20a%20diamond.\">Please refer this link for shear Example</a>\n",
    "\n",
    "5)Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "                               width_shift_range=0.1, \n",
    "                               height_shift_range=0.1, \n",
    "                               rescale=1/255, \n",
    "                               shear_range=0.2, \n",
    "                               zoom_range=0.2, \n",
    "                               fill_mode='nearest'\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all the Images have been resized to 350 x 350 in black and white mode and used <br>\n",
    "\n",
    "Batch size of 16 is used <br>\n",
    "\n",
    "The images have been loaded from the Directory(recognizance/train) in B/W mode with ImageDataGenerator <br>\n",
    "\n",
    "The ImageDataGenerator Now reads 16 images in B/W mode each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 163 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_shape = (350,350,1)\n",
    "batch_size = 16\n",
    "train_image_gen = image_gen.flow_from_directory('../input/recognizance/train',color_mode='grayscale',\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='binary',seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN model is implemented using the Keras Library. <br>\n",
    "\n",
    "Loss Function used - Binary Crossentropy <br>\n",
    "Optimizer - Adam <br>\n",
    "Epochs Used - 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Flatten, Dense, Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 6s 546ms/step - loss: 2.3309 - accuracy: 0.5215\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 5s 487ms/step - loss: 0.5953 - accuracy: 0.6810\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 6s 513ms/step - loss: 0.6011 - accuracy: 0.6810\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 6s 518ms/step - loss: 0.4565 - accuracy: 0.8344\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 6s 501ms/step - loss: 0.2958 - accuracy: 0.8834\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 6s 503ms/step - loss: 0.2793 - accuracy: 0.9018\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 6s 526ms/step - loss: 0.3335 - accuracy: 0.8834\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 5s 490ms/step - loss: 0.2142 - accuracy: 0.8896\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 5s 490ms/step - loss: 0.1568 - accuracy: 0.9325\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 6s 526ms/step - loss: 0.1892 - accuracy: 0.9202\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 6s 538ms/step - loss: 0.2341 - accuracy: 0.9264\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 6s 545ms/step - loss: 0.2334 - accuracy: 0.9018\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 5s 485ms/step - loss: 0.2180 - accuracy: 0.9202\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 5s 481ms/step - loss: 0.2183 - accuracy: 0.9141\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 5s 490ms/step - loss: 0.2937 - accuracy: 0.8896\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 5s 491ms/step - loss: 0.2066 - accuracy: 0.9202\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 6s 502ms/step - loss: 0.1547 - accuracy: 0.9387\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 5s 482ms/step - loss: 0.1157 - accuracy: 0.9387\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 5s 484ms/step - loss: 0.2612 - accuracy: 0.9202\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 6s 551ms/step - loss: 0.2509 - accuracy: 0.8896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fece4147390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(350,350,1), activation='relu',))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3),activation='relu',))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu',))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit_generator(generator=train_image_gen,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 6s 553ms/step - loss: 0.1171 - accuracy: 0.9509\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 5s 485ms/step - loss: 0.0961 - accuracy: 0.9755\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 5s 482ms/step - loss: 0.1047 - accuracy: 0.9632\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 6s 507ms/step - loss: 0.0853 - accuracy: 0.9755\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 5s 490ms/step - loss: 0.0932 - accuracy: 0.9509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fec6c7b89d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_image_gen,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 6s 518ms/step - loss: 0.2323 - accuracy: 0.9264\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 5s 480ms/step - loss: 0.1194 - accuracy: 0.9448\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 6s 528ms/step - loss: 0.0938 - accuracy: 0.9693\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 6s 504ms/step - loss: 0.1006 - accuracy: 0.9509\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 6s 522ms/step - loss: 0.1579 - accuracy: 0.9264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fec6c73cfd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_image_gen,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the filenames inside the test folder are read and stored in a array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = []\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/recognizance/test/'):\n",
    "    for filename in filenames:\n",
    "        files.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then each corresponding image is loaded using Keras.image.load_img in B/W mode and with dimension of 350 <br>\n",
    "\n",
    "Then the class of the Image(Positive/negative) is predicted and the value is appended in a Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in files:\n",
    "    img = image.load_img('../input/recognizance/test/'+i, target_size=(350,350,1),color_mode = \"grayscale\")\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img/255\n",
    "    pred.append(model.predict_classes(img)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the File names with their classes are made into a Dataframe for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(pred,files).reset_index()\n",
    "sub.columns = ['image','label']\n",
    "sub.to_csv('sub4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip sub4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"modelweights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
